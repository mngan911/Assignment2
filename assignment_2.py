# -*- coding: utf-8 -*-
"""Assignment 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yevnD8YxFA5Wvau8hPlxAbVts0f5lx5u
"""

### Assignment 2

"""# Q1"""

# Question 1

import pandas as pd
import numpy as np
from scipy.optimize import minimize

data = pd.read_csv('https://www.stlouisfed.org/-/media/project/frbstl/stlouisfed/research/fred-md/monthly/current.csv?sc_lang=en&hash=80445D12401C59CF716410F3F7863B64')

# Clean the data to get the log difference of INDPRO

data['INDPRO'] = pd.to_numeric(data['INDPRO'], errors='coerce')
data = data.dropna(subset=['INDPRO'])
data['log_diff_INDPRO'] = np.log(data['INDPRO']).diff().dropna()

y = data['log_diff_INDPRO'].dropna().values

# Define the conditional Log Likelihood Function
def conditional_log_likelihood(params, y):
    c, phi1, phi2, sigma = params
    residuals = y[2:] - c - phi1 * y[1:-1] - phi2 * y[:-2]
    ll = -0.5 * np.sum(np.log(2 * np.pi * sigma**2) + (residuals**2) / sigma**2)
    return -ll

# Define the unconditional Log Likelihood Funtion
def unconditional_log_likelihood(params, y):
    c, phi1, phi2, sigma = params
    var = sigma**2 / (1 - phi1**2 - phi2**2)
    ll_init = -0.5 * np.sum(np.log(2 * np.pi * var) + (y[:2]**2) / var)
    residuals = y[2:] - c - phi1 * y[1:-1] - phi2 * y[:-2]
    ll = -0.5 * np.sum(np.log(2 * np.pi * sigma**2) + (residuals**2) / sigma**2)
    return -(ll + ll_init)

# Create initial parameters and bounds
initial_params = [0, 0.5, 0.5, 1]
bounds = [(None, None), (None, None), (None, None), (1e-6, None)]

# Get Conditional Likelihood parameters by minimizing the negatice -log-likelihood, therefore maximizing Log-likelihood
result_cond = minimize(conditional_log_likelihood, initial_params, args=(data[2:],),
                       method='L-BFGS-B', bounds=bounds)
print("Conditional Likelihood:")
print(f"c: {result_cond.x[0]:.6f}, phi1: {result_cond.x[1]:.6f}, phi2: {result_cond.x[2]:.6f}, sigma: {result_cond.x[3]:.6f}")

result_cond = minimize(conditional_log_likelihood, initial_params, args=(y[2:],),
                       method='L-BFGS-B', bounds=bounds)
print("Conditional Likelihood:")
print(f"c: {result_cond.x[0]:.6f}, phi1: {result_cond.x[1]:.6f}, phi2: {result_cond.x[2]:.6f}, sigma: {result_cond.x[3]:.6f}")

# Get Unconditional Likelihood parameters by minimizing the negatice -log-likelihood, therefore maximizing Log-likelihood
result_uncond = minimize(unconditional_log_likelihood, initial_params, args=(data,),
                         method='L-BFGS-B', bounds=bounds)
print("Unconditional Likelihood:")
print(f"c: {result_uncond.x[0]:.6f}, phi1: {result_uncond.x[1]:.6f}, phi2: {result_uncond.x[2]:.6f}, sigma: {result_uncond.x[3]:.6f}")

result_uncond = minimize(unconditional_log_likelihood, initial_params, args=(y,),
                         method='L-BFGS-B', bounds=bounds)
print("Unconditional Likelihood:")
print(f"c: {result_uncond.x[0]:.6f}, phi1: {result_uncond.x[1]:.6f}, phi2: {result_uncond.x[2]:.6f}, sigma: {result_uncond.x[3]:.6f}")

# Define the OLS estimation for generalized AR(p) model
def fit_ar_ols(data, p):
    """
    OLS estimation for AR(p) model with a constant term.

    data: observed data.
    p: order of the AR model.
    """
    T = len(data)
    Y = data[p:]  # from p
    X = np.column_stack([data[p - i - 1:T - i - 1] for i in range(p)])
    X = np.column_stack((np.ones(X.shape[0]), X))  # c

    # OLS beta = (X'X)^-1 X'Y
    XTX = np.dot(X.T, X)
    XTY = np.dot(X.T, Y)
    beta_hat = np.linalg.solve(XTX, XTY)

    return beta_hat

# Extract AR(2) coefficients
p = 2
beta_hat = fit_ar_ols(data, p)
print("Estimated AR coefficients:", beta_hat)

p = 2
beta_hat = fit_ar_ols(y, p)
print("Estimated AR coefficients:", beta_hat)

"""# Q2-3"""

# Question 2 & 3

import numpy as np
import pandas as pd
from scipy.optimize import minimize
from scipy.stats import norm

# Clean dataset to get log diff

data = pd.read_csv('https://www.stlouisfed.org/-/media/project/frbstl/stlouisfed/research/fred-md/monthly/current.csv?sc_lang=en&hash=80445D12401C59CF716410F3F7863B64')
data = data.iloc[1:].copy()
data['INDPRO'] = pd.to_numeric(data['INDPRO'], errors='coerce')
data.dropna(subset=['INDPRO'], inplace=True)

log_diff = np.log(data['INDPRO']).diff().dropna()

# Define the AR likelihood funtion
def ar_likelihood(params, y, p):
    c = params[0]
    phi = params[1:p+1]  # AR
    sigma2 = params[-1]

    T = len(y)
    residuals = y[p:] - c - np.dot(np.column_stack([y[p-j-1:T-j-1] for j in range(p)]), phi)
    log_likelihood = (-T/2 * np.log(2 * np.pi * sigma2) - np.sum(residuals**2) / (2 * sigma2))

    return -log_likelihood

# AR estimate
def estimate_ar_parameters(y, p):
    params_initial = np.zeros(p+2)
    params_initial[-1] = 1.0  # initial variance = 1

    bounds = [(None, None)] + [(-1, 1) for _ in range(p)] + [(1e-6, None)]
    result = minimize(ar_likelihood, params_initial, args=(y, p), bounds=bounds)

    if result.success:
        return result.x
    else:
        raise Exception("fault:", result.message)

# Plugging data of INDPRO into defined function to get Unconditional Log-likelihood and Estimated parameters
p = 2
params = estimate_ar_parameters(log_diff, p)
print("Estimated parameters:", params)
data = log_diff

#Finding Unconditional Log-likelihood
unconditional_log_likelihood = ar_likelihood(params, data, p)
print("Unconditional Log-Likelihood:", unconditional_log_likelihood)

# OLS to AR paras
def fit_ar_ols(y, p):
    T = len(y)
    Y = y[p:]
    X = np.column_stack([y[p-i-1:T-i-1] for i in range(p)])
    X = np.column_stack((np.ones(X.shape[0]), X))

    beta_hat = np.linalg.solve(X.T @ X, X.T @ Y)
    return beta_hat

# Create the MLE and OLS Estimation parameters
p = 2
params_mle = estimate_ar_parameters(log_diff, p)
params_ols = fit_ar_ols(log_diff, p)

print("MLE Estimation Not Restore Originals:", params_mle)
print("OLS Estimation:", params_ols)

# prediction for future 8 months
future_steps = 8
predictions_mle, predictions_ols = [], []
past_values = list(log_diff[-p:])

for _ in range(future_steps):
    next_pred_mle = params_mle[0] + sum(params_mle[i+1] * past_values[-(i + 1)] for i in range(p))
    next_pred_ols = params_ols[0] + sum(params_ols[i+1] * past_values[-(i + 1)] for i in range(p))

    predictions_mle.append(next_pred_mle)
    predictions_ols.append(next_pred_ols)
    past_values.append(next_pred_mle)

# reduction to the original scale
data['INDPRO_forecast_mle'] = np.nan
data['INDPRO_forecast_ols'] = np.nan
last_value = data['INDPRO'].iloc[-1]

forecast_values_mle = [last_value * np.exp(sum(predictions_mle[:i+1])) for i in range(future_steps)]
forecast_values_ols = [last_value * np.exp(sum(predictions_ols[:i+1])) for i in range(future_steps)]
actual_values = data['INDPRO'].iloc[-future_steps:].values


print("Prediction for Future 8 Months (MLE):", forecast_values_mle)
print("Prediction for Future 8 Months (OLS):", forecast_values_ols)
print("Actual value for 8 months:", actual_values)

# calculation of forecast error
actual_values = data['INDPRO'].iloc[-future_steps:].values
mse_mle = np.mean((forecast_values_mle - actual_values) ** 2)
mse_ols = np.mean((forecast_values_ols - actual_values) ** 2)

forecast = {
    "Month": range(1, 9),  # Months 1 to 8
    "MLE Prediction": forecast_values_mle,
    "OLS Prediction": forecast_values_ols,
    "Actual Value": actual_values
}

forecast_table = pd.DataFrame(forecast)
forecast_table.loc[len(forecast_table)] = ["MSE", mse_mle, mse_ols, np.nan]

print(forecast_table)

if mse_mle < mse_ols:
    print("The smaller prediction error of the MLE method indicates that its prediction performance on this dataset is better than that of OLS.")
else:
    print("The smaller prediction error of the OLS method indicates that its prediction performance on this dataset is better than that of MLE.")

print("Possible reasons include:\n1. The OLS method is more robust to larger samples and may be less affected by outliers.\n2. The MLE method relies on assumptions about the error distribution, which may affect its predictive effectiveness if the data do not satisfy the normality assumption.")

# Plotting forecast and actual value to compare
import matplotlib.pyplot as plt
steps = range(1, future_steps + 1)

# Plot the forecasted values vs actual value
plt.figure(figsize=(12, 6))
plt.plot(steps, forecast_values_mle, label='MLE Forecast', color='red', linestyle='--', marker='o')
plt.plot(steps, forecast_values_ols, label='OLS Forecast', color='green', linestyle='-.', marker='s')
plt.plot(steps, actual_values, label='Actual', color='blue', linestyle='-', marker='x')

plt.title('Industrial Production Forecast for Next 8 Months')
plt.xlabel('Step(h)')
plt.ylabel('INDPRO Value')
plt.xticks(steps)
plt.legend()
plt.grid(True)
plt.ylim(90, 110)

plt.show()

"""Graphically, the forecast is quite close to real data"""